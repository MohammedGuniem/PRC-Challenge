{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c96c56-ac59-485d-a850-bf37237376a8",
   "metadata": {},
   "source": [
    "<h1>Read & Summarize Trajactory Files.ipynb</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d29760dc-9415-4aa6-bff2-35d871e93db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7963dbd1-5cda-4e1e-817d-005cf42770a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(flight_ids) = 474972 flights\n"
     ]
    }
   ],
   "source": [
    "challenge_set = pd.read_csv('../challenge_set.csv')\n",
    "flight_ids = list(challenge_set['flight_id'].astype(int).unique())\n",
    "\n",
    "submission_set = pd.read_csv('../submission_set.csv')\n",
    "flight_ids += list(submission_set['flight_id'].astype(int).unique())\n",
    "\n",
    "print(f\"{len(flight_ids) = } flights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdee797b-7ac2-4bd3-bfdf-ceb0a7043ad6",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.5 GiB for an array with shape (11, 225892937) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m         current_trajectory_df \u001b[38;5;241m=\u001b[39m pq\u001b[38;5;241m.\u001b[39mParquetDataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/trajectory_files/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrajectory_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mto_pandas()\n\u001b[0;32m      8\u001b[0m         filtered_trajactory_df \u001b[38;5;241m=\u001b[39m current_trajectory_df[current_trajectory_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mflight_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\u001b[38;5;241m.\u001b[39misin(flight_ids)]\n\u001b[1;32m----> 9\u001b[0m         trajectory_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrajectory_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltered_trajactory_df\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Display the filtered DataFrame\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(trajectory_df)\u001b[38;5;250m \u001b[39m\u001b[38;5;132;01m= }\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\prc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[1;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[0;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[0;32m    383\u001b[0m     objs,\n\u001b[0;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m    393\u001b[0m )\n\u001b[1;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\prc\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[0;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[1;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[0;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\prc\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:177\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[1;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[0;32m    167\u001b[0m vals \u001b[38;5;241m=\u001b[39m [ju\u001b[38;5;241m.\u001b[39mblock\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;28;01mfor\u001b[39;00m ju \u001b[38;5;129;01min\u001b[39;00m join_units]\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mis_extension:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# _is_uniform_join_units ensures a single dtype, so\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;66;03m#  we can use np.concatenate, which is more performant\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# expected \"Union[_SupportsArray[dtype[Any]],\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# _NestedSequence[_SupportsArray[dtype[Any]]]]\"\u001b[39;00m\n\u001b[1;32m--> 177\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_1d_only_ea_dtype(blk\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# TODO(EA2D): special-casing not needed with 2D EAs\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     values \u001b[38;5;241m=\u001b[39m concat_compat(vals, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, ea_compat_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.5 GiB for an array with shape (11, 225892937) and data type float64"
     ]
    }
   ],
   "source": [
    "file_names = os.listdir(\"../data/trajectory_files\")\n",
    "\n",
    "trajectory_df = pd.DataFrame({})\n",
    "\n",
    "for trajectory_file_name in file_names:\n",
    "    if \".parquet\" in trajectory_file_name:\n",
    "        current_trajectory_df = pq.ParquetDataset(f'../data/trajectory_files/{trajectory_file_name}').read().to_pandas()\n",
    "        filtered_trajactory_df = current_trajectory_df[current_trajectory_df['flight_id'].astype(int).isin(flight_ids)]\n",
    "        trajectory_df = pd.concat([trajectory_df, filtered_trajactory_df], ignore_index=True)\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(f\"{len(trajectory_df) = }\")\n",
    "display(trajectory_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac019f-69b9-4ea4-a4f7-0abc079f4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stat(\n",
    "    dataframe: pd.DataFrame, \n",
    "    group_by_column: str, \n",
    "    target_column: str,\n",
    "    stat_type: str,\n",
    "    value_type: str = 'float64'\n",
    ") -> pd.Series | None:\n",
    "    result = None\n",
    "    if stat_type == 'median':\n",
    "        result = df.groupby(group_by_column).apply(lambda group: group[target_column].median(), meta=('value', value_type)).compute()\n",
    "    elif stat_type == 'mean':\n",
    "        result = df.groupby(group_by_column).apply(lambda group: group[target_column].mean(), meta=('value', value_type)).compute()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cc12bf-aca3-40fd-9b8c-c4f780bcb260",
   "metadata": {},
   "outputs": [],
   "source": [
    "latitude_median = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='latitude', stat_type='median')\n",
    "longitude_median = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='longitude', stat_type='median')\n",
    "altitude_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='altitude', stat_type='mean', value_type='int64')\n",
    "groundspeed_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='groundspeed', stat_type='mean', value_type='int64')\n",
    "track_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='track', stat_type='mean')\n",
    "vertical_rate_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='vertical_rate', stat_type='mean', value_type='int64')\n",
    "track_unwrapped_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='track_unwrapped', stat_type='mean')\n",
    "u_component_of_wind_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='u_component_of_wind', stat_type='mean')\n",
    "v_component_of_wind_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='v_component_of_wind', stat_type='mean')\n",
    "temperature_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='temperature', stat_type='mean')\n",
    "specific_humidity_mean = calculate_stat(dataframe=trajectory_df, group_by_column='flight_id', target_column='specific_humidity', stat_type='mean')\n",
    "\n",
    "trajactory_summary_df = pd.DataFrame({\n",
    "    \"latitude_median\": latitude_median,\n",
    "    \"longitude_median\": longitude_median,\n",
    "    \"altitude_mean\": altitude_mean,\n",
    "    \"groundspeed_mean\": groundspeed_mean,\n",
    "    \"track_mean\": track_mean,\n",
    "    \"vertical_rate_mean\": vertical_rate_mean,\n",
    "    \"track_unwrapped_mean\": track_unwrapped_mean,\n",
    "    \"u_component_of_wind_mean\": u_component_of_wind_mean,\n",
    "    \"v_component_of_wind_mean\": v_component_of_wind_mean,\n",
    "    \"temperature\": temperature_mean,\n",
    "    \"specific_humidity\": specific_humidity_mean\n",
    "})\n",
    "\n",
    "display(trajactory_summary_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dece9f18-889e-4ae8-8da7-0f9cd8f7d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(path: str, dataframe: pd.DataFrame) -> None:\n",
    "    dataframe.to_csv(path, index=False)\n",
    "    print(f\"{path} is saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa4a6cd-3657-4c42-9528-56c5b921f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dataframe(path=\"../data/trajactory_summary.csv\", dataframe=trajactory_summary_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
