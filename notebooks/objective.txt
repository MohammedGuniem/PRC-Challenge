*** Plan ***
1- Done: Process challenge set (split date and time and drop not needed columns). -> processed_challenge_set.csv
2- Done: Process submission set (split date and time and drop not needed columns). -> processed_submission_set.csv
3- Done: Gather stats from trajectories. -> summarized_trajectory.csv
4- Done: Merge trajectory stats with processed challenge set. -> challenge_set_with_trajectories.csv
4- Done: Merge trajectory stats with process submission set. -> submission_set_with_trajectories.csv
5- Done: Concat (processed challenge set+submission set), label encode, then split. -> encoded_challenge_set.csv, encoded_submission_set.csv
6- Done: Grid Search XGBoost model based on encoded_challenge_set, then plot importance
7- Done: Build models with less features by selecting the most important features one at a time
8- Done: Cluster datapoints and view RMSE on k-fold for the cluster model

**- Build models with less features by selecting the most correlated features to tow one at a time

*** Data Size ***
369013 in challenge_set
= 369013 Training datapoint ( 369013/527162 = 0,70 %)
105959 in submission_set
52190 in final_submission_set
= 158149 Submission datapoint ( 158149/527162 = 0,30 %)
>> Test size should be 0.3
