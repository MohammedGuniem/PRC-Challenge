*** Plan ***
- Done: Process challenge set (split date and time and drop not needed columns). -> processed_challenge_set.csv
- Done: Process submission set (split date and time and drop not needed columns). -> processed_submission_set.csv
- Ongoing: Gather stats from trajectories. -> summarized_trajectory.csv
- Merge trajectory stats with processed challenge set. -> challenge_set_with_trajectories.csv
- Merge trajectory stats with process submission set. -> submission_set_with_trajectories.csv
- Concat (processed challenge set+submission set), label encode, then split. -> encoded_challenge_set.csv, encoded_submission_set.csv
- Normalize or Standarize
- Grid Search, Evaluate XGBoost model based on encoded_challenge_set, then plot importance

*** Data Size ***
369013 in challenge_set
= 369013 Training datapoint ( 369013/527162 = 0,70 %)
105959 in submission_set
52190 in final_submission_set
= 158149 Submission datapoint ( 158149/527162 = 0,30 %)
>> Test size should be 0.3
